# Evaluating OpenAI's Whisper for Robustness with 'In The Wild' Datasets
We are evaluating [OpenAI's whisper](https://github.com/openai/whisper/tree/main?tab=readme-ov-file) under 'in the wild' datasets using the WER metric to understand its robustness. The aim is to see if Whisper can be used as an additional feature to Mobile X Lab's VeriLight system by focusing on hashing live speech transcriptions as an additional form of verification to VeriLight's visual detection system.

## Setup
Create a conda environment with Python 3.9:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`conda create -n whispereval python=3.9`\
Install the necessary packages:\
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`pip install -r requirements.txt`
## Dataset

## Evaluation
